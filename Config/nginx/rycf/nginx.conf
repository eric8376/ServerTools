user  nginx;

# The number of CPU cores
worker_processes  24;

error_log  /data/log/nginx/error.log error;
pid        /var/run/nginx.pid;

#ulimit -n 200000
worker_rlimit_nofile 200000;

events {
    # Determines how many clients will be served by each worker process.
    # (Max clients = worker_connections * worker_processes)
    # "Max clients" is also limited by the number of socket connections available on the system (~64k)
    worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';

    log_format  proxy  '$remote_addr - $remote_user [$time_local] "$request" '
                       '$status $body_bytes_sent "$http_referer" '
                       '"$http_user_agent" "$http_x_forwarded_for" '
                       '$upstream_addr $upstream_status $upstream_cache_status $upstream_response_time';

    #access_log  /var/log/nginx/access.log  main;
    access_log off; 

    server_tokens off;

    client_max_body_size 5m; 
    client_body_buffer_size 1024k;

    # Sendfile copies data between one FD and other from within the kernel.
    # More efficient than read() + write(), since the requires transferring data to and from the user space.
    sendfile        on;
    # Tcp_nopush causes nginx to attempt to send its HTTP response head in one packet,
    # instead of using partial frames. This is useful for prepending headers before calling sendfile,
    # or for throughput optimization.
    tcp_nopush     on;
    # don't buffer data-sends (disable Nagle algorithm). Good for sending frequent small bursts of data in real time.
    tcp_nodelay on;

    # Timeout for keep-alive connections. Server will close connections after this time.
    keepalive_timeout  30;
    # Number of requests a client can make over the keep-alive connection. This is set high for testing.
    keepalive_requests 100000;
    # allow the server to close the connection after a client stops responding. Frees up socket-associated memory.
    reset_timedout_connection on;
    # send the client a "request timed out" if the body is not loaded by this time. Default 60.
    client_body_timeout 10;
    # If the client stops reading data, free up the stale client connection after this much time. Default 60.
    send_timeout 2;

    # Caches information about open FDs, freqently accessed files.
    # Changing this setting, in my environment, brought performance up from 560k req/sec, to 904k req/sec.
    # I recommend using some varient of these options, though not the specific values listed below.
    open_file_cache max=200000 inactive=20s;
    open_file_cache_valid 30s;
    open_file_cache_min_uses 2;
    open_file_cache_errors on;

    # Compression. Reduces the amount of data that needs to be transferred over the network
    gzip on;
    gzip_http_version 1.1;
    gzip_min_length  50k;  
    gzip_proxied expired no-cache no-store private auth;
    gzip_types text/plain text/css text/xml text/javascript application/javascript application/x-javascript application/xml application/json image/jpeg image/gif image/png;
    gzip_vary on;  
    gzip_buffers     4 16k;  
    gzip_comp_level 2;  
    gzip_disable "MSIE [1-6]\.";

    proxy_cache_path /data/cache/cache_rycf levels=1:2 keys_zone=cache_rycf:200m inactive=1d max_size=1g;

    include upstream.conf;

    include /etc/nginx/conf.d/*.conf;
}
